Index: rdma-core/ib2roce/ib2roce.c
===================================================================
--- rdma-core.orig/ib2roce/ib2roce.c
+++ rdma-core/ib2roce/ib2roce.c
@@ -72,7 +72,6 @@
 #include <infiniband/umad_cm.h>
 #include <infiniband/umad_str.h>
 #include <execinfo.h>
-#include "packet.h"
 #include "errno.h"
 #include "bth_hdr.h"
 #include "ib_hdrs.h"
@@ -88,16 +87,13 @@
 #include "beacon.h"
 #include "cli.h"
 #include "pgm.h"
-
+#include "endpoint.h"
 
 #include "ibraw.h"
 #include "cma-hdr.h"
 
 #define MIN(a,b) (((a)<(b))?(a):(b))
 
-#define ROCE_PORT 4791
-#define ETHERTYPE_ROCE 0x8915
-
 // #define HAVE_MSTFLINT
 // #define DEBUG
 // #define UNICAST
@@ -109,7 +105,6 @@ static bool debug = false;		/* Stay in f
 static bool update_requested = false;	/* Received SIGUSR1. Dump all MC data details */
 #ifdef UNICAST
 static bool unicast = false;		/* Bridge unicast packets */
-static bool flow_steering = false;	/* Use flow steering to filter packets */
 static bool raw = false;		/* Use raw channels */
 static bool packet_socket = false;	/* Do not use RAW QPs, use packet socket instead */
 #endif
@@ -131,36 +126,6 @@ struct buf;
 
 typedef void event_callback(void *);
 
-/*
- * The forwarding struct describes the forwarding for datagrams
- * coming from a source QP to another QP at an endpoint.
- * This is singly linked list attache to the endpoints
- */
-struct forward {
-	struct endpoint *dest;
-	struct forward *next;
-	uint32_t source_qp, dest_qp;
-	uint32_t dest_qkey;
-};
-
-/*
- * Address information for an endpoint.
- * ah points to the address stucture needed to send data to
- * this endpoint. The rest are basically keys to lookup
- * the ah.
- *
- * Each endpoint has a list of connections. Packets
- * coming in from the host
- */
-struct endpoint {
-	struct i2r_interface *i;
-	struct in_addr addr;
-	union ibv_gid gid;
-	uint16_t lid;
-	struct ibv_ah *ah;
-	struct forward *forwards;
-};
-
 #ifdef UNICAST
 /*
  * A Unicastconnection to a certain port and host with
@@ -379,123 +344,6 @@ err:
 	return NULL;
 }
 
-static void arm_channels(struct core_info *core);
-
-/*
- * Polling function for each core enabling low latency operations.
- * This currently does not support NUMA affinities. It may need
- * to benefit from manually setting affinities but -- aside from the
- * obvious need to run on the NIC numa node that it serves --
- * the Linux scheduler should take care of most of what is needed.
- *
- * NOHZ should be enabled though to avoid hiccups from timer interrupts
- */
-static void scan_cqs(void *private)
-{
-	struct core_info *core = private;
-	int i;
-	int cqs;
-	struct rdma_channel *c;
-	struct ibv_wc wc[10];
-
-	for(i = 0; i < core->nr_channels; i++) {
-		cqs = ibv_poll_cq(core->channel[i].cq, 10, wc);
-		if (cqs) {
-			c = core->channel + i;
-
-			if (cqs > 0)
-				process_cqes(c, wc, cqs);
-			else {
-				logg(LOG_WARNING, "Busyloop: CQ polling failed with: %s on %s\n",
-						errname(), c->text);
-				core->state = core_err;
-				continue;
-			}
-		}
-	}
-}
-
-
-static void *busyloop(void *private)
-{
-	struct core_info *core = private;
-	unsigned cpu;
-
-	pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);
-	numa_run_on_node(core->numa_node);
-
-	current->state = core_init;
-
-	cpu = sched_getcpu();
-	logg(LOG_NOTICE, "Busyloop started (core %ld) on CPU %d NUMA=%d\n", current - core_infos, cpu, current->numa_node);
-
-	/*
-	 * Initialize relevant data structures for this thread. These must be allocated
-	 * from the thread to ensure that they are thread local
-	 */
-	arm_channels(core);
-
-	core->state = core_running;
-	busy_event_loop(scan_cqs, core);
-	return NULL;
-}
-
-static void get_core_logs(void *private)
-{
-	struct core_info *c = private;
-	char msg[251];
-	unsigned len;
-
-	while ((len = ring_get(&c->ring, msg, sizeof(msg) - 1))) {
-		int prio;
-
-		msg[len] = 0;
-		prio = msg[0] - '0';
-		logg(prio, "%s\n", msg + 1);
-	}
-	add_event(now + milliseconds(100), get_core_logs, c, "Get Core Logs");
-}
-
-/* Called after all the channels have been setup */
-static void start_cores(void)
-{
-	int j;
-
-	multithreaded = true;
-
-	for(j = 0; j < cores; j++) {
-		struct core_info *ci = core_infos + j;
-
-		if (!ci->nr_channels)
-			continue;
-
-		ring_init(&ci->ring);
-		get_core_logs(ci);
-
-		if (pthread_create(&ci->thread, &ci->attr, &busyloop, core_infos + j))
-			panic("Pthread create failed: %s\n", errname());
-	}
-}
-
-static void stop_cores(void)
-{
-	int i;
-
-	for(i = 0; i < cores; i++) {
-		struct core_info *ci = core_infos + i;
-
-		if (!ci->thread)
-			continue;
-
-		pthread_cancel(ci->thread);
-
-		if (pthread_join(ci->thread, NULL))
-			panic("pthread_join failed: %s\n", errname());
-	}
-
-	multithreaded = false;
-}
- 
 static char *payload_dump(uint8_t *p)
 {
 	return _hexbytes(p, 48);
@@ -563,97 +411,6 @@ static void dump_buf_grh(struct buf *buf
 }
 #endif
 
-/*
- * Handling of RDMA work requests
- */
-static void post_receive(struct rdma_channel *c)
-{
-	struct ibv_recv_wr recv_wr, *recv_failure;
-	struct ibv_sge sge;
-	int ret = 0;
-
-	if (!c || !nextbuffer)
-		return;
-
-	if (c->active_receive_buffers >= c->nr_receive)
-		return;
-
-	recv_wr.next = NULL;
-	recv_wr.sg_list = &sge;
-	recv_wr.num_sge = 1;
-
-	sge.length = DATA_SIZE;
-	sge.lkey = c->mr->lkey;
-
-	while (c->active_receive_buffers < c->nr_receive) {
-
-		struct buf *buf = alloc_buffer(c);
-
-		if (!buf) {
-			logg(LOG_WARNING, "%s: No free buffers left\n", c->text);
-			return;
-		}
-
-		/* Use the buffer address for the completion handler */
-		recv_wr.wr_id = (uint64_t)buf;
-		sge.addr = (uint64_t)buf->raw;
-		ret = ibv_post_recv(c->qp, &recv_wr, &recv_failure);
-		if (ret) {
-			free_buffer(buf);
-			errno = ret;
-			logg(LOG_ERR, "ibv_post_recv failed: %s:%s\n", c->text, errname());
-			return;
-                }
-		c->active_receive_buffers++;
-	}
-}
-
-static void post_receive_buffers(void)
-{
-	struct i2r_interface *i;
-
-	for(i = i2r; i < i2r + NR_INTERFACES; i++) {
-		post_receive(i->multicast);
-#ifdef UNICAST
-		post_receive(i->raw);
-		post_receive(i->qp1);
-		post_receive(i->ud);
-#endif
-	}
-}
-
-
-static void channel_destroy(struct rdma_channel *c)
-{
-	if (!c)
-		return;
-
-	if (c->type == channel_rdmacm) {
-
-		if (c->qp)
-			rdma_destroy_qp(c->id);
-
-		if (c->cq)
-			ibv_destroy_cq(c->cq);
-
-		ibv_dereg_mr(c->mr);
-		if (c->pd)
-			ibv_dealloc_pd(c->pd);
-
-		rdma_destroy_id(c->id);
-	} else
-	if (c->type != channel_packet)	{
-		ibv_destroy_qp(c->qp);
-
-		if (c->cq)
-			ibv_destroy_cq(c->cq);
-
-	}
-	clear_channel_bufs(c);
-	if (!c->core)
-		free(c);
-}
-
 #ifdef HAVE_MSTFLINT
 static void shutdown_sniffer(int arg) {
 	struct i2r_interface *i = i2r + INFINIBAND;
@@ -768,53 +525,6 @@ err:
 		     i->rdma_name, reason, errname());
 }
 
-#ifdef UNICAST
-static void start_channel(struct rdma_channel *c)
-{
-	int ret;
-
-	if (!c)
-		return;
-
-	if (c->type == channel_rdmacm)
-       		return;
-
-	c->attr.qp_state = IBV_QPS_RTR;
-
-	ret = ibv_modify_qp(c->qp, &c->attr, IBV_QP_STATE);
-	if (ret)
-		logg(LOG_CRIT, "ibv_modify_qp: Error when moving %s to RTR state. %s\n", c->text, errname());
-
-	if (c->type == channel_ud || c->type == channel_qp1) {
-
-		c->attr.qp_state = IBV_QPS_RTS;
-		ret = ibv_modify_qp(c->qp, &c->attr, IBV_QP_STATE | IBV_QP_SQ_PSN);
-
-		if (ret)
-			logg(LOG_CRIT, "ibv_modify_qp: Error when moving %s to RTS state. %s\n", c->text, errname());
-
-	}
-	logg(LOG_NOTICE, "QP %s moved to state %s: QPN=%d\n",
-		 c->text,  (c->type == channel_ud || c->type == channel_qp1)? "RTS/RTR" : "RTR", c->qp->qp_num);
-}
-
-static void stop_channel(struct rdma_channel *c)
-{
-	int ret;
-
-	if (c->type == channel_rdmacm)
-		return;
-
-	c->attr.qp_state = IBV_QPS_INIT;
-
-	ret = ibv_modify_qp(c->qp, &c->attr, IBV_QP_STATE);
-	if (ret)
-		logg(LOG_CRIT, "ibv_modify_qp: Error when moving %s to INIT state. %s\n", c->text, errname());
-
-	logg(LOG_NOTICE, "QP %s moved to state QPS_INIT\n", c->text);
-}
-#endif
-
 static int allocate_rdmacm_qp(struct rdma_channel *c, bool multicast)
 {
 	struct ibv_qp_init_attr_ex init_qp_attr_ex;
@@ -1329,57 +1039,6 @@ static struct rdma_unicast *new_rdma_uni
 	return ra;
 }
 
-static void setup_flow(struct rdma_channel *c)
-{
-	if (!c)
-		return;
-
-	/* Sadly flow steering is not supported on Infiniband */
-	if (c->i == i2r + INFINIBAND)
-		return;
-
-	if (flow_steering) {
-			struct i2r_interface *i = c->i;
-			enum interfaces in = i - i2r;
-			struct i2r_interface *di = i2r + (in ^ 1);
-			unsigned netmask = di->if_netmask.sin_addr.s_addr;
-			struct {
-				struct ibv_flow_attr attr;
-				struct ibv_flow_spec_ipv4 ipv4;
-				struct ibv_flow_spec_tcp_udp udp;
-			} flattr = {
-				{
-					0, IBV_FLOW_ATTR_SNIFFER, sizeof(flattr),
-					0, 2, i->port, 0
-				},
-				{
-					IBV_FLOW_SPEC_IPV4, sizeof(struct ibv_flow_spec_ipv4),
-					{ 0, di->if_addr.sin_addr.s_addr & netmask },
-					{ 0, netmask }
-				},
-				{
-					IBV_FLOW_SPEC_UDP, sizeof(struct ibv_flow_spec_tcp_udp),
-					{ ROCE_PORT, ROCE_PORT},
-					{ 0xffff, 0xffff}
-				}
-			};
-
-			c->flow = ibv_create_flow(c->qp, &flattr.attr);
-
-	} else {
-
-		struct ibv_flow_attr flattr = {
-				0, IBV_FLOW_ATTR_SNIFFER, sizeof(struct ibv_flow_spec),
-				0, 0, c->i->port, 0
-		};
-
-		c->flow = ibv_create_flow(c->qp, &flattr);
-	}
-
-	if (!c->flow)
-		logg(LOG_ERR, "Failure to create flow on %s. Errno %s\n", c->text, errname());
-}
-
 static void unicast_packet(struct rdma_channel *c, struct buf *buf, struct in_addr dest_addr)
 {
 	unsigned long l;
@@ -1394,51 +1053,6 @@ static void unicast_packet(struct rdma_c
 }
 #endif
 
-static void list_endpoints(struct i2r_interface *i)
-{
-	char buf[1000] = "";
-	int n = 0;
-	struct endpoint *e[10];
-	unsigned offset = 0;
-	unsigned nr;
-
-	if (!i->context || !i->ep)
-		return;
-
-	while ((nr = hash_get_objects(i->ep, offset, 10, (void **)e))) {
-		int j;
-
-		for (j = 0; j < nr; j++) {
-			struct endpoint *ep = e[j];
-
-			if (ep->lid) {
-
-				if (ep->addr.s_addr)
-					n += snprintf(buf + n, sizeof(buf) - n, " %s/lid=%d", inet_ntoa(ep->addr), ep->lid);
-				else
-					n += snprintf(buf + n, sizeof(buf) - n, " lid=%d", ep->lid);
-
-			} else
-				n += snprintf(buf + n, sizeof(buf) - n, " %s", inet_ntoa(ep->addr));
-
-			if (ep->forwards) {
-				struct forward *f = ep->forwards;
-
-				while (f) {
-					n += snprintf(buf + n, sizeof(buf) - n, "[0x%x->%s:%x/%x]",
-						f->source_qp, inet_ntoa(f->dest->addr), f->dest_qp, f->dest_qkey);
-
-					f = f->next;
-				}
-			}
-		}
-
-		offset += 10;
-	}
-	if (n)
-		logg(LOG_NOTICE, "Known Endpoints on %s:%s\n", i->text, buf);
-}
-
 #ifdef UNICAST
 /*
  * Establish a forwarding for UD unicast packets. Used on UD packet
@@ -3185,41 +2799,6 @@ static void setup_timed_events(void)
 	calculate_pps(NULL);
 }
 
-static void arm_channels(struct core_info *core)
-{
-	struct i2r_interface *i;
-
-	for(i = i2r; i < i2r + NR_INTERFACES; i++)
-	   if (i->context) {
-
-		/* And request notifications if something happens */
-		if (i->multicast && core == i->multicast->core) {
-			ibv_req_notify_cq(i->multicast->cq, 0);
-		}
-#ifdef UNICAST
-		if (i->raw && core == i->raw->core &&
-			       (i->raw->type == channel_raw || i->raw->type == channel_ibraw)) {
-			start_channel(i->raw);
-			ibv_req_notify_cq(i->raw->cq, 0);
-
-			setup_flow(i->raw);
-		}
-
-		if (i->ud && core == i->ud->core) {
-			start_channel(i->ud);
-			ibv_req_notify_cq(i->ud->cq, 0);
-		}
-
-		if (i->qp1 && core == i->qp1->core) {
-			start_channel(i->qp1);
-			ibv_req_notify_cq(i->qp1->cq, 0);
-		}
-#endif
-	}
-
-}
-
-
 static void update_status(int x)
 {
 	update_requested = true;
@@ -3416,8 +2995,6 @@ int main(int argc, char **argv)
 	init_buf();	/* Setup interface registers memmory */
 	numa_run_on_node(-1);
 
-	init_pgm_streams();
-
 	setup_interface(INFINIBAND);
 	setup_interface(ROCE);
 
Index: rdma-core/ib2roce/pgm.c
===================================================================
--- rdma-core.orig/ib2roce/pgm.c
+++ rdma-core/ib2roce/pgm.c
@@ -86,7 +86,7 @@ struct pgm_record {
 	unsigned len;			/* Length of the message */
 };
 
-void init_pgm_streams(void)
+static void init_pgm_streams(void)
 {
 	struct i2r_interface *i;
 
@@ -512,5 +512,6 @@ __attribute__((constructor))
 static void pgm_init(void)
 {
 	register_concom("tsi", true, 0, "Show PGM info", tsi_cmd);
+	init_pgm_streams();
 }
 
Index: rdma-core/ib2roce/pgm.h
===================================================================
--- rdma-core.orig/ib2roce/pgm.h
+++ rdma-core/ib2roce/pgm.h
@@ -46,6 +46,5 @@ enum pgm_mode { pgm_none, pgm_passthroug
 extern enum pgm_mode pgm_mode;
 
 bool pgm_process(struct rdma_channel *c, struct mc *m, struct buf *buf);
-void init_pgm_streams(void);
 
 #endif
Index: rdma-core/ib2roce/logging.c
===================================================================
--- rdma-core.orig/ib2roce/logging.c
+++ rdma-core/ib2roce/logging.c
@@ -201,7 +201,28 @@ static void brief_status(void)
 	list_endpoints(i2r + ROCE);
 }
 
-/* Continous printing of the log line on the console */
+/*
+ * Retrieving logs from other cores
+ */
+void get_core_logs(void *private)
+{
+	struct core_info *c = private;
+	char msg[251];
+	unsigned len;
+
+	while ((len = ring_get(&c->ring, msg, sizeof(msg) - 1))) {
+		int prio;
+
+		msg[len] = 0;
+		prio = msg[0] - '0';
+		logg(prio, "%s\n", msg + 1);
+	}
+	add_event(now + milliseconds(100), get_core_logs, c, "Get Core Logs");
+}
+
+/*
+ * Continous printing of the log line on the console
+ */
 static int log_interval;
 
 static void verbose_set(char *optarg)
Index: rdma-core/ib2roce/logging.h
===================================================================
--- rdma-core.orig/ib2roce/logging.h
+++ rdma-core/ib2roce/logging.h
@@ -60,5 +60,7 @@ static inline char *_hexbytes(uint8_t *q
 	return hexbytes(q, len, ' ');
 }
 
+void get_core_logs(void *private);
+
 #endif
 
Index: rdma-core/ib2roce/channel.c
===================================================================
--- rdma-core.orig/ib2roce/channel.c
+++ rdma-core/ib2roce/channel.c
@@ -77,6 +77,169 @@ const char *stats_text[nr_stats] = {
 };
 
 
+static bool flow_steering = false;	/* Use flow steering to filter packets */
+
+static void setup_flow(struct rdma_channel *c)
+{
+	if (!c)
+		return;
+
+	/* Sadly flow steering is not supported on Infiniband */
+	if (c->i == i2r + INFINIBAND)
+		return;
+
+	if (flow_steering) {
+			struct i2r_interface *i = c->i;
+			enum interfaces in = i - i2r;
+			struct i2r_interface *di = i2r + (in ^ 1);
+			unsigned netmask = di->if_netmask.sin_addr.s_addr;
+			struct {
+				struct ibv_flow_attr attr;
+				struct ibv_flow_spec_ipv4 ipv4;
+				struct ibv_flow_spec_tcp_udp udp;
+			} flattr = {
+				{
+					0, IBV_FLOW_ATTR_SNIFFER, sizeof(flattr),
+					0, 2, i->port, 0
+				},
+				{
+					IBV_FLOW_SPEC_IPV4, sizeof(struct ibv_flow_spec_ipv4),
+					{ 0, di->if_addr.sin_addr.s_addr & netmask },
+					{ 0, netmask }
+				},
+				{
+					IBV_FLOW_SPEC_UDP, sizeof(struct ibv_flow_spec_tcp_udp),
+					{ ROCE_PORT, ROCE_PORT},
+					{ 0xffff, 0xffff}
+				}
+			};
+
+			c->flow = ibv_create_flow(c->qp, &flattr.attr);
+
+	} else {
+
+		struct ibv_flow_attr flattr = {
+				0, IBV_FLOW_ATTR_SNIFFER, sizeof(struct ibv_flow_spec),
+				0, 0, c->i->port, 0
+		};
+
+		c->flow = ibv_create_flow(c->qp, &flattr);
+	}
+
+	if (!c->flow)
+		logg(LOG_ERR, "Failure to create flow on %s. Errno %s\n", c->text, errname());
+}
+
+
+void channel_destroy(struct rdma_channel *c)
+{
+	if (!c)
+		return;
+
+	if (c->type == channel_rdmacm) {
+
+		if (c->qp)
+			rdma_destroy_qp(c->id);
+
+		if (c->cq)
+			ibv_destroy_cq(c->cq);
+
+		ibv_dereg_mr(c->mr);
+		if (c->pd)
+			ibv_dealloc_pd(c->pd);
+
+		rdma_destroy_id(c->id);
+	} else
+	if (c->type != channel_packet)	{
+		ibv_destroy_qp(c->qp);
+
+		if (c->cq)
+			ibv_destroy_cq(c->cq);
+
+	}
+	clear_channel_bufs(c);
+	if (!c->core)
+		free(c);
+}
+
+void start_channel(struct rdma_channel *c)
+{
+	int ret;
+
+	if (!c)
+		return;
+
+	if (c->type == channel_rdmacm)
+       		return;
+
+	c->attr.qp_state = IBV_QPS_RTR;
+
+	ret = ibv_modify_qp(c->qp, &c->attr, IBV_QP_STATE);
+	if (ret)
+		logg(LOG_CRIT, "ibv_modify_qp: Error when moving %s to RTR state. %s\n", c->text, errname());
+
+	if (c->type == channel_ud || c->type == channel_qp1) {
+
+		c->attr.qp_state = IBV_QPS_RTS;
+		ret = ibv_modify_qp(c->qp, &c->attr, IBV_QP_STATE | IBV_QP_SQ_PSN);
+
+		if (ret)
+			logg(LOG_CRIT, "ibv_modify_qp: Error when moving %s to RTS state. %s\n", c->text, errname());
+
+	}
+	logg(LOG_NOTICE, "QP %s moved to state %s: QPN=%d\n",
+		 c->text,  (c->type == channel_ud || c->type == channel_qp1)? "RTS/RTR" : "RTR", c->qp->qp_num);
+}
+
+void stop_channel(struct rdma_channel *c)
+{
+	int ret;
+
+	if (c->type == channel_rdmacm)
+		return;
+
+	c->attr.qp_state = IBV_QPS_INIT;
+
+	ret = ibv_modify_qp(c->qp, &c->attr, IBV_QP_STATE);
+	if (ret)
+		logg(LOG_CRIT, "ibv_modify_qp: Error when moving %s to INIT state. %s\n", c->text, errname());
+
+	logg(LOG_NOTICE, "QP %s moved to state QPS_INIT\n", c->text);
+}
+
+
+void arm_channels(struct core_info *core)
+{
+	struct i2r_interface *i;
+
+	for(i = i2r; i < i2r + NR_INTERFACES; i++)
+	   if (i->context) {
+
+		/* And request notifications if something happens */
+		if (i->multicast && core == i->multicast->core) {
+			ibv_req_notify_cq(i->multicast->cq, 0);
+		}
+		if (i->raw && core == i->raw->core &&
+			       (i->raw->type == channel_raw || i->raw->type == channel_ibraw)) {
+			start_channel(i->raw);
+			ibv_req_notify_cq(i->raw->cq, 0);
+
+			setup_flow(i->raw);
+		}
+
+		if (i->ud && core == i->ud->core) {
+			start_channel(i->ud);
+			ibv_req_notify_cq(i->ud->cq, 0);
+		}
+
+		if (i->qp1 && core == i->qp1->core) {
+			start_channel(i->qp1);
+			ibv_req_notify_cq(i->qp1->cq, 0);
+		}
+	}
+
+}
+
 int channel_stats(char *b, struct rdma_channel *c, const char *interface, const char *type)
 {
 	int n = 0;
@@ -127,4 +290,7 @@ __attribute__((constructor))
 static void channel_init(void)
 {
 	register_concom("channels", true, 0, "Print information about communication channels", channels_cmd);
+
+	register_enable("flow", false, &flow_steering, NULL, "on", "off", NULL,
+		"Enable flow steering to limit the traffic on the RAW sockets [Experimental, Broken]");
 }
Index: rdma-core/ib2roce/channel.h
===================================================================
--- rdma-core.orig/ib2roce/channel.h
+++ rdma-core/ib2roce/channel.h
@@ -67,6 +67,10 @@
 
 #include "fifo.h"
 
+
+#define ROCE_PORT 4791
+#define ETHERTYPE_ROCE 0x8915
+
 enum interfaces { INFINIBAND, ROCE, NR_INTERFACES };
 
 extern const char *interfaces_text[NR_INTERFACES];
@@ -137,5 +141,11 @@ static inline void st(struct rdma_channe
 int channel_stats(char *b, struct rdma_channel *c, const char *interface, const char *type);
 void channel_stat(struct rdma_channel *c);
 
+void start_channel(struct rdma_channel *c);
+void stop_channel(struct rdma_channel *c);
+
+void arm_channels(struct core_info *core);
+void channel_destroy(struct rdma_channel *c);
+
 #endif
 
Index: rdma-core/ib2roce/endpoint.c
===================================================================
--- rdma-core.orig/ib2roce/endpoint.c
+++ rdma-core/ib2roce/endpoint.c
@@ -527,6 +527,265 @@ static unsigned show_endpoints(char *b)
 	return n;
 }
 
+#ifdef UNICAST
+static void resolve_start(struct rdma_unicast *);
+
+static void zap_channel(struct rdma_unicast *ru)
+{
+	struct buf *buf;
+
+	while ((buf = fifo_get(&ru->pending)))		/* Drop pending I/O */
+		free_buffer(buf);
+
+	channel_destroy(ru->c);
+	if (ru->sin.sin_addr.s_addr) {
+		ru->c = NULL;
+		ru->state = UC_NONE;
+	} else
+		/* Temporary struct that can go away now */
+		free(ru);
+}
+
+/* Drop the first entry from the list of items to resolve */
+static void resolve_end(struct rdma_unicast *ru)
+{
+	struct i2r_interface *i = ru->i;
+
+	if (ru != fifo_get(&i->resolve_queue))
+		panic("Nothing in fifo\n");
+
+	if (ru->state == UC_CONNECTED) {
+		struct buf *buf;
+
+		while ((buf = fifo_get(&ru->pending)))		/* Send pending I/O */
+			send_buf(buf, ru);
+	} else
+		zap_channel(ru);
+
+	/* Resolve the next address */
+	ru = fifo_first(&i->resolve_queue);
+	if (ru)
+		resolve_start(ru);
+}
+
+static void resolve_start(struct rdma_unicast *ru)
+{
+	struct i2r_interface *i = ru->i;
+
+	if (!ru->c) {
+		struct sockaddr_in *sin;
+
+		sin = calloc(1, sizeof(struct sockaddr_in));
+		sin->sin_family = AF_INET;
+		sin->sin_addr = i->if_addr.sin_addr;
+		sin->sin_port = 0;
+		ru->c = new_rdma_channel(i, channel_incoming);
+		ru->c->ru = ru;
+	}
+
+	if (rdma_resolve_addr(ru->c->id, NULL, (struct sockaddr *)&ru->sin, 2000) == 0) {
+		ru->state = UC_ADDR_REQ;
+		return;
+	}
+
+	logg(LOG_ERR, "rdma_resolve_addr error %s on %s for %s:%d\n",
+		errname(), ru->c->text, inet_ntoa(ru->sin.sin_addr), ntohs(ru->sin.sin_port));
+
+	resolve_end(ru);
+}
+
+/* Resolve Address and send buffer when done */
+static void resolve(struct rdma_unicast *ru)
+{
+	struct i2r_interface *i = ru->i;
+
+	if (fifo_put(&i->resolve_queue, ru))
+		resolve_start(ru);
+}
+#endif
+
+#ifdef UNICAST
+static struct rdma_unicast *new_rdma_unicast(struct i2r_interface *i, struct sockaddr_in *sin)
+{
+	struct rdma_unicast *ra = calloc(1, sizeof(struct rdma_unicast));
+
+	ra->i = i;
+	memcpy(&ra->sin, sin, sizeof(struct sockaddr_in));
+	fifo_init(&ra->pending);
+	return ra;
+}
+
+static void setup_flow(struct rdma_channel *c)
+{
+	if (!c)
+		return;
+
+	/* Sadly flow steering is not supported on Infiniband */
+	if (c->i == i2r + INFINIBAND)
+		return;
+
+	if (flow_steering) {
+			struct i2r_interface *i = c->i;
+			enum interfaces in = i - i2r;
+			struct i2r_interface *di = i2r + (in ^ 1);
+			unsigned netmask = di->if_netmask.sin_addr.s_addr;
+			struct {
+				struct ibv_flow_attr attr;
+				struct ibv_flow_spec_ipv4 ipv4;
+				struct ibv_flow_spec_tcp_udp udp;
+			} flattr = {
+				{
+					0, IBV_FLOW_ATTR_SNIFFER, sizeof(flattr),
+					0, 2, i->port, 0
+				},
+				{
+					IBV_FLOW_SPEC_IPV4, sizeof(struct ibv_flow_spec_ipv4),
+					{ 0, di->if_addr.sin_addr.s_addr & netmask },
+					{ 0, netmask }
+				},
+				{
+					IBV_FLOW_SPEC_UDP, sizeof(struct ibv_flow_spec_tcp_udp),
+					{ ROCE_PORT, ROCE_PORT},
+					{ 0xffff, 0xffff}
+				}
+			};
+
+			c->flow = ibv_create_flow(c->qp, &flattr.attr);
+
+	} else {
+
+		struct ibv_flow_attr flattr = {
+				0, IBV_FLOW_ATTR_SNIFFER, sizeof(struct ibv_flow_spec),
+				0, 0, c->i->port, 0
+		};
+
+		c->flow = ibv_create_flow(c->qp, &flattr);
+	}
+
+	if (!c->flow)
+		logg(LOG_ERR, "Failure to create flow on %s. Errno %s\n", c->text, errname());
+}
+
+static void unicast_packet(struct rdma_channel *c, struct buf *buf, struct in_addr dest_addr)
+{
+	unsigned long l;
+
+	memcpy(&l, buf->cur, sizeof(long));
+	if (l == BEACON_SIGNATURE) {
+		beacon_received(buf);
+		return;
+	}
+
+	dump_buf_grh(buf);
+}
+#endif
+
+#ifdef UNICAST
+/*
+ * Establish a forwarding for UD unicast packets. Used on UD packet
+ * reception to find the destination.
+ *
+ * This function only adds the forward. Check if there is an existing
+ * forward before calling this function.
+ */
+static void add_forward(struct endpoint *source, uint32_t source_qp, struct endpoint *dest, uint32_t dest_qp, uint32_t qkey)
+{
+	struct forward *f = calloc(1, sizeof(struct forward));
+
+	f->dest = dest;
+	f->dest_qp = dest_qp;
+	f->dest_qkey = qkey;
+	f->source_qp = source_qp;
+
+	f->next = source->forwards;
+	source->forwards = f;
+}
+
+/*
+ * Find the forwarding entry for traffic coming in from a source QP on one side
+ *
+ * dest == NULL enables wildcard search just based on source_qp
+ *
+ * source_qp = 0 indicated that the source_qp is not known yet.
+ */
+static struct forward *find_forward(struct endpoint *source, struct endpoint *dest, uint32_t source_qp)
+{
+	struct forward *f = source->forwards;
+
+	while (f && f->source_qp != source_qp && (!dest || f->dest == dest))
+		f = f->next;
+
+	return f;
+}
+
+#if 0
+/*
+ * Remove a forward and indicate if something was there before.
+ *
+ * This can be used to remove an entry before calling
+ * add_forward.
+ */
+static bool remove_forward(struct endpoint *source, uint32_t source_qp)
+{
+	struct forward *f = source->forwards;
+	struct forward *prior = NULL;
+
+	while (f && f->source_qp != source_qp) {
+		prior = f;
+		f = f->next;
+	}
+
+	if (f) {
+		if (prior) {
+			prior->next = f->next;
+		} else {
+			source->forwards = f->next;
+		}
+		free(f);
+		return true;
+	} else
+		return false;
+}
+#endif
+
+/*
+ * Remove all forwards of an endpoint and indicate how many
+ * were removed.
+ */
+static unsigned int remove_forwards(struct endpoint *source)
+{
+	unsigned int n = 0;
+
+	while (source->forwards) {
+		struct forward *f = source->forwards;
+
+		source->forwards = f->next;
+		free(f);
+		n++;
+	}
+	return n;
+}
+#endif
+
+#if 0
+/*
+ * Update the forwarder if the source point changes
+ */
+static struct forward *update_forward(struct endpoint *source, uint32_t old_source_qp, uint32_t new_source_qp)
+{
+	struct forward *f = source->forwards;
+
+	while (f && f->source_qp != old_source_qp)
+		f = f->next;
+
+	if (!f)
+		return NULL;
+
+	f->source_qp = new_source_qp;
+	return f;
+}
+#endif
+
 static void endpoints_cmd(char *parameters)
 {
 	int n;
Index: rdma-core/ib2roce/interfaces.c
===================================================================
--- rdma-core.orig/ib2roce/interfaces.c
+++ rdma-core/ib2roce/interfaces.c
@@ -542,7 +542,7 @@ void handle_async_event(void *private)
 /*
  * Handling of RDMA work requests
  */
-static void post_receive(struct rdma_channel *c)
+void post_receive(struct rdma_channel *c)
 {
 	struct ibv_recv_wr recv_wr, *recv_failure;
 	struct ibv_sge sge;
@@ -584,12 +584,25 @@ static void post_receive(struct rdma_cha
 	}
 }
 
+void post_receive_buffers(void)
+{
+	struct i2r_interface *i;
+
+	for(i = i2r; i < i2r + NR_INTERFACES; i++) {
+		post_receive(i->multicast);
+		post_receive(i->raw);
+		post_receive(i->qp1);
+		post_receive(i->ud);
+	}
+}
+
+
 static void reset_flags(struct buf *buf)
 {
 	memset(&buf->ip_valid, 0, (void *)&buf->ip_csum_ok - (void *)&buf->ip_valid);
 }
 
-void process_cqes(struct rdma_channel *c, struct ibv_wc *wc, unsigned cqs)
+static void process_cqes(struct rdma_channel *c, struct ibv_wc *wc, unsigned cqs)
 {
 	unsigned j;
 
@@ -663,6 +676,40 @@ void process_cqes(struct rdma_channel *c
 	post_receive(c);
 }
 
+/*
+ * Polling function for each core enabling low latency operations.
+ * This currently does not support NUMA affinities. It may need
+ * to benefit from manually setting affinities but -- aside from the
+ * obvious need to run on the NIC numa node that it serves --
+ * the Linux scheduler should take care of most of what is needed.
+ *
+ * NOHZ should be enabled though to avoid hiccups from timer interrupts
+ */
+void scan_cqs(void *private)
+{
+	struct core_info *core = private;
+	int i;
+	int cqs;
+	struct rdma_channel *c;
+	struct ibv_wc wc[10];
+
+	for(i = 0; i < core->nr_channels; i++) {
+		cqs = ibv_poll_cq(core->channel[i].cq, 10, wc);
+		if (cqs) {
+			c = core->channel + i;
+
+			if (cqs > 0)
+				process_cqes(c, wc, cqs);
+			else {
+				logg(LOG_WARNING, "Busyloop: CQ polling failed with: %s on %s\n",
+						errname(), c->text);
+				core->state = core_err;
+				continue;
+			}
+		}
+	}
+}
+
 void handle_comp_event(void *private)
 {
 	struct ibv_comp_channel *events = private;
Index: rdma-core/ib2roce/interfaces.h
===================================================================
--- rdma-core.orig/ib2roce/interfaces.h
+++ rdma-core/ib2roce/interfaces.h
@@ -101,11 +101,9 @@ struct i2r_interface {
 	struct ibv_context *context;		/* Not for RDMA CM use */
 	struct rdma_event_channel *rdma_events;
 	struct rdma_channel *multicast;
-#ifdef UNICAST
 	struct rdma_channel *qp1;		/* Channel for QP1 communications but not QP1 (userspace) */
 	struct rdma_channel *ud;		/* Regular data */
 	struct rdma_channel *raw;
-#endif
 	struct ibv_comp_channel *comp_events;
 	struct ibv_cq *cq;
 	struct ibv_pd *pd;
@@ -164,7 +162,8 @@ const char *inet6_ntoa(void *x);
 void set_rate(struct mc *m);
 void set_rates(void);
 
-void process_cqes(struct rdma_channel *c, struct ibv_wc *wc, unsigned cqs);
+/* Scan a cores rdma channels for completion queue entries */
+void scan_cqs(void *private);
 
 int check_rdma_device(enum interfaces i, int port, char *name,
 	       struct ibv_context *c, struct ibv_port_attr *a, struct ibv_device_attr *d);
@@ -172,4 +171,7 @@ int check_rdma_device(enum interfaces i,
 /* Scan through available RDMA devices in order to locate the devices for bridging */
 int find_rdma_devices(void);
 
+void post_receive(struct rdma_channel *c);
+void post_receive_buffers(void);
+
 #endif
Index: rdma-core/ib2roce/sched.c
===================================================================
--- rdma-core.orig/ib2roce/sched.c
+++ rdma-core/ib2roce/sched.c
@@ -77,7 +77,7 @@ thread_local uint64_t now;
 thread_local struct core_info *current = NULL;
 
 int cores = 0;
-bool latency = false;
+static bool latency = false;
 
 static bool terminated = false;
 
@@ -225,10 +225,8 @@ int event_loop(void)
 	return 0;
 }
 
-int busy_event_loop(event_callback *callback, void *private)
+static int busy_event_loop(event_callback *callback, void *private)
 {
-
-
 	while (!terminated) {
 		cpu_relax();
 		callback(private);
@@ -238,6 +236,70 @@ int busy_event_loop(event_callback *call
 }
 
 
+void *busyloop(void *private)
+{
+	struct core_info *core = private;
+	unsigned cpu;
+
+	pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, NULL);
+	numa_run_on_node(core->numa_node);
+
+	current->state = core_init;
+
+	cpu = sched_getcpu();
+	logg(LOG_NOTICE, "Busyloop started (core %ld) on CPU %d NUMA=%d\n", current - core_infos, cpu, current->numa_node);
+
+	/*
+	 * Initialize relevant data structures for this thread. These must be allocated
+	 * from the thread to ensure that they are thread local
+	 */
+	arm_channels(core);
+
+	core->state = core_running;
+	busy_event_loop(scan_cqs, core);
+	return NULL;
+}
+
+/* Called after all the channels have been setup */
+void start_cores(void)
+{
+	int j;
+
+	multithreaded = true;
+
+	for(j = 0; j < cores; j++) {
+		struct core_info *ci = core_infos + j;
+
+		if (!ci->nr_channels)
+			continue;
+
+		ring_init(&ci->ring);
+		get_core_logs(ci);
+
+		if (pthread_create(&ci->thread, &ci->attr, &busyloop, core_infos + j))
+			panic("Pthread create failed: %s\n", errname());
+	}
+}
+
+void stop_cores(void)
+{
+	int i;
+
+	for(i = 0; i < cores; i++) {
+		struct core_info *ci = core_infos + i;
+
+		if (!ci->thread)
+			continue;
+
+		pthread_cancel(ci->thread);
+
+		if (pthread_join(ci->thread, NULL))
+			panic("pthread_join failed: %s\n", errname());
+	}
+
+	multithreaded = false;
+}
+
 static void channel_zap(struct rdma_channel *c)
 {
 	c->last_snapshot = 0;
Index: rdma-core/ib2roce/sched.h
===================================================================
--- rdma-core.orig/ib2roce/sched.h
+++ rdma-core/ib2roce/sched.h
@@ -99,15 +99,31 @@ extern thread_local struct core_info *cu
 #define cpu_relax()	asm volatile("rep; nop")
 
 typedef void event_callback(void *);
+
+/* Callback at a certain time */
 void add_event(uint64_t when, event_callback *callback, void *private, const char *text);
+
+/* Callback when data on a filedescriptor becomes available */
 void register_callback(event_callback *callback, int fd, void *private);
 
+
 int64_t time_to_next_event(void);	/* Time till next event */
+
 uint64_t run_events(void);	/* Run events that are scheduled */
-int event_loop(void);		/* Enter loop running events and servicing fd callbacks */
-int busy_event_loop(event_callback *callback, void *private);	/* Enter loop running events and servicing fd callbacks */
-void terminate(int x);		/* Terminate the event loop */
 
-int get_timer_list(char *b, char separator);	/* List the timers and put the data into the buffer */
+/* Event loop to be used on the slow threads. Services FD and times events */
+int event_loop(void);
+
+/* Polling event loop. Polling occurs in the callback. Also runs timed events */
+void *busyloop(void *private);
+
+/* terminates the event loop */
+void terminate(int x);
+
+/* Get a textual representation of the timers */
+int get_timer_list(char *b, char separator);
+
+void start_cores(void);
+void stop_cores(void);
 
 #endif
